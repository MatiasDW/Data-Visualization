{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f18fa604-2a71-4035-a38c-6262fa4532ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getReviewsFromAmazon() missing 1 required positional argument: 'num_pages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m samsung_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.amazon.com/product-reviews/B08WF4XDMF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     57\u001b[0m sony_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.amazon.com/product-reviews/B08WJMSS8H\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 59\u001b[0m samsung_reviews, samsung_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mgetReviewsFromAmazon\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamsung_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m sony_reviews, sony_ratings \u001b[38;5;241m=\u001b[39m getReviewsFromAmazon(sony_url)\n\u001b[0;32m     62\u001b[0m samsung_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(samsung_reviews)\n",
      "\u001b[1;31mTypeError\u001b[0m: getReviewsFromAmazon() missing 1 required positional argument: 'num_pages'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def getReviewsFromAmazon(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    review_elements = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    for review_element in review_elements:\n",
    "        review_body = review_element.find('span', {'data-hook': 'review-body'})\n",
    "        review_rating_element = review_element.find('i', {'data-hook': 'review-star-rating'})\n",
    "        review_rating = float(review_rating_element.find('span').text.split()[0])\n",
    "        \n",
    "        if review_body is not None:\n",
    "            reviews.append(review_body.text)\n",
    "        ratings.append(review_rating)\n",
    "    return reviews, ratings\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = STOPWORDS, min_font_size = 10).generate(text)\n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()\n",
    "\n",
    "def generate_histogram(ratings):\n",
    "    plt.hist(ratings, bins=5, range=(1,5))\n",
    "    plt.title('Histogram of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "def getReviewsFromAmazon(base_url, num_pages):\n",
    "    review_list = []\n",
    "    for i in range(1, num_pages + 1):\n",
    "        page_url = base_url + \"/pageNumber=\" + str(i)\n",
    "        page = requests.get(page_url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        reviews = soup.find_all('span', {'data-hook': 'review-body'})\n",
    "        for review in reviews:\n",
    "            review_list.append(review.text)\n",
    "        time.sleep(5)  # pause for 1 second between requests to avoid getting blocked\n",
    "    return review_list\n",
    "\n",
    "def get_sentiment(review):\n",
    "    analysis = TextBlob(review)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "samsung_url = 'https://www.amazon.com/product-reviews/B08WF4XDMF'\n",
    "sony_url = 'https://www.amazon.com/product-reviews/B08WJMSS8H'\n",
    "\n",
    "samsung_reviews, samsung_ratings = getReviewsFromAmazon(samsung_url)\n",
    "sony_reviews, sony_ratings = getReviewsFromAmazon(sony_url)\n",
    "\n",
    "samsung_text = ' '.join(samsung_reviews)\n",
    "sony_text = ' '.join(sony_reviews)\n",
    "\n",
    "generate_wordcloud(samsung_text)\n",
    "generate_wordcloud(sony_text)\n",
    "\n",
    "generate_histogram(samsung_ratings)\n",
    "generate_histogram(sony_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d664f8e5-09e2-4da9-84f4-0dfb4484e94d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m samsung_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(samsung_reviews)\n\u001b[0;32m     63\u001b[0m sony_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sony_reviews)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mgenerate_wordcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamsung_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m generate_wordcloud(sony_text)\n\u001b[0;32m     68\u001b[0m generate_histogram(samsung_ratings)\n",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m, in \u001b[0;36mgenerate_wordcloud\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_wordcloud\u001b[39m(text):\n\u001b[1;32m---> 26\u001b[0m     wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopwords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTOPWORDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_font_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), facecolor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \n\u001b[0;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud) \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:410\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    408\u001b[0m frequencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(frequencies\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frequencies) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe need at least 1 word to plot a word cloud, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(frequencies))\n\u001b[0;32m    412\u001b[0m frequencies \u001b[38;5;241m=\u001b[39m frequencies[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_words]\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# largest entry will be 1\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def getReviewsFromSinglePage(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    review_elements = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    for review_element in review_elements:\n",
    "        review_body = review_element.find('span', {'data-hook': 'review-body'})\n",
    "        review_rating_element = review_element.find('i', {'data-hook': 'review-star-rating'})\n",
    "        review_rating = float(review_rating_element.find('span').text.split()[0])\n",
    "        \n",
    "        if review_body is not None:\n",
    "            reviews.append(review_body.text)\n",
    "        ratings.append(review_rating)\n",
    "    return reviews, ratings\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = STOPWORDS, min_font_size = 10).generate(text)\n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()\n",
    "\n",
    "def generate_histogram(ratings):\n",
    "    plt.hist(ratings, bins=5, range=(1,5))\n",
    "    plt.title('Histogram of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def getReviewsFromMultiplePages(base_url, num_pages):\n",
    "    review_list = []\n",
    "    ratings_list = []\n",
    "    for i in range(1, num_pages + 1):\n",
    "        page_url = base_url + \"/pageNumber=\" + str(i)\n",
    "        page = requests.get(page_url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        reviews, ratings = getReviewsFromSinglePage(page_url)\n",
    "        for review, rating in zip(reviews, ratings):\n",
    "            review_list.append(review)\n",
    "            ratings_list.append(rating)\n",
    "        time.sleep(5)  # pause for 1 second between requests to avoid getting blocked\n",
    "    return review_list, ratings_list\n",
    "\n",
    "samsung_url = 'https://www.amazon.com/product-reviews/B08WF4XDMF'\n",
    "sony_url = 'https://www.amazon.com/product-reviews/B08WJMSS8H'\n",
    "\n",
    "num_pages = 5\n",
    "\n",
    "samsung_reviews, samsung_ratings = getReviewsFromMultiplePages(samsung_url, num_pages)\n",
    "sony_reviews, sony_ratings = getReviewsFromMultiplePages(sony_url, num_pages)\n",
    "\n",
    "samsung_text = ' '.join(samsung_reviews)\n",
    "sony_text = ' '.join(sony_reviews)\n",
    "\n",
    "generate_wordcloud(samsung_text)\n",
    "generate_wordcloud(sony_text)\n",
    "\n",
    "generate_histogram(samsung_ratings)\n",
    "generate_histogram(sony_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175174b-9902-49fb-8eb0-2d5a75558bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
